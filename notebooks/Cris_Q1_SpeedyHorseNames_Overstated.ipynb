{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53457975/pyspark-udf-function-error-in-lambda-function\n",
    "import os\n",
    "os.environ['OBJC_DISABLE_INITIALIZE_FORK_SAFETY'] = 'YES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# https://spark.apache.org/docs/latest/job-scheduling.html\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook2-cris\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"7g\").\\\n",
    "        config(\"spark.cores.max\", \"3\").\\\n",
    "        config(\"spark.executor.instances\", \"1\").\\\n",
    "        config(\"spark.executor.cores\", \"3\").\\\n",
    "        config(\"spark.mongodb.input.uri\",\"mongodb://mongo1:27017,mongo2:27018,mongo3:27019/database.horses_collection?replicaSet=rs0\").\\\n",
    "        config(\"spark.mongodb.output.uri\",\"mongodb://mongo1:27017,mongo2:27018,mongo3:27019/database.horses_collection?replicaSet=rs0\").\\\n",
    "        config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n",
    "        getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/21 23:03:08 WARN MongoInferSchema: Field 'bsp' contains conflicting types converting to StringType\n"
     ]
    }
   ],
   "source": [
    "#reading dataframes from MongoDB\n",
    "\n",
    "# sampleSize - https://stackoverflow.com/a/56255303\n",
    "df = spark.read.format(\"mongo\").option('sampleSize', 50000).load()\n",
    "df.createOrReplaceTempView(\"mongo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- clk: string (nullable = true)\n",
      " |-- mc: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- marketDefinition: struct (nullable = true)\n",
      " |    |    |    |-- betDelay: integer (nullable = true)\n",
      " |    |    |    |-- bettingType: string (nullable = true)\n",
      " |    |    |    |-- bspMarket: boolean (nullable = true)\n",
      " |    |    |    |-- bspReconciled: boolean (nullable = true)\n",
      " |    |    |    |-- complete: boolean (nullable = true)\n",
      " |    |    |    |-- countryCode: string (nullable = true)\n",
      " |    |    |    |-- crossMatching: boolean (nullable = true)\n",
      " |    |    |    |-- discountAllowed: boolean (nullable = true)\n",
      " |    |    |    |-- eachWayDivisor: double (nullable = true)\n",
      " |    |    |    |-- eventId: string (nullable = true)\n",
      " |    |    |    |-- eventName: string (nullable = true)\n",
      " |    |    |    |-- eventTypeId: string (nullable = true)\n",
      " |    |    |    |-- inPlay: boolean (nullable = true)\n",
      " |    |    |    |-- marketBaseRate: double (nullable = true)\n",
      " |    |    |    |-- marketTime: string (nullable = true)\n",
      " |    |    |    |-- marketType: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- numberOfActiveRunners: integer (nullable = true)\n",
      " |    |    |    |-- numberOfWinners: integer (nullable = true)\n",
      " |    |    |    |-- openDate: string (nullable = true)\n",
      " |    |    |    |-- persistenceEnabled: boolean (nullable = true)\n",
      " |    |    |    |-- regulators: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- runners: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- adjustmentFactor: double (nullable = true)\n",
      " |    |    |    |    |    |-- bsp: string (nullable = true)\n",
      " |    |    |    |    |    |-- id: integer (nullable = true)\n",
      " |    |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |    |-- removalDate: string (nullable = true)\n",
      " |    |    |    |    |    |-- sortPriority: integer (nullable = true)\n",
      " |    |    |    |    |    |-- status: string (nullable = true)\n",
      " |    |    |    |-- runnersVoidable: boolean (nullable = true)\n",
      " |    |    |    |-- settledTime: string (nullable = true)\n",
      " |    |    |    |-- status: string (nullable = true)\n",
      " |    |    |    |-- suspendTime: string (nullable = true)\n",
      " |    |    |    |-- timezone: string (nullable = true)\n",
      " |    |    |    |-- turnInPlayEnabled: boolean (nullable = true)\n",
      " |    |    |    |-- venue: string (nullable = true)\n",
      " |    |    |    |-- version: integer (nullable = true)\n",
      " |    |    |-- rc: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- ltp: double (nullable = true)\n",
      " |    |    |    |    |-- id: integer (nullable = true)\n",
      " |-- op: string (nullable = true)\n",
      " |-- pt: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+---+-------------+\n",
      "|                 _id|       clk|                  mc| op|           pt|\n",
      "+--------------------+----------+--------------------+---+-------------+\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699287, [0...|mcm|1462537993283|\n",
      "|[619e9dd8677066b2...|2480249142|[[1.124699287, [0...|mcm|1462540135101|\n",
      "|[619e9dd8677066b2...|2481803835|[[1.124699287, [0...|mcm|1462555384075|\n",
      "|[619e9dd8677066b2...|2481994285|[[1.124699287,, [...|mcm|1462557371191|\n",
      "|[619e9dd8677066b2...|2482055516|[[1.124699287,, [...|mcm|1462557910955|\n",
      "|[619e9dd8677066b2...|2482072939|[[1.124699287,, [...|mcm|1462558089056|\n",
      "|[619e9dd8677066b2...|2482078964|[[1.124699287,, [...|mcm|1462558150717|\n",
      "|[619e9dd8677066b2...|2482083965|[[1.124699287, [0...|mcm|1462558199155|\n",
      "|[619e9dd8677066b2...|2482177634|[[1.124699287, [0...|mcm|1462559078531|\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699285, [0...|mcm|1462537993283|\n",
      "|[619e9dd8677066b2...|2480212422|[[1.124699285, [0...|mcm|1462539800697|\n",
      "|[619e9dd8677066b2...|2480409166|[[1.124699285, [0...|mcm|1462541919372|\n",
      "|[619e9dd8677066b2...|2481526806|[[1.124699285,, [...|mcm|1462552870198|\n",
      "|[619e9dd8677066b2...|2481622628|[[1.124699285, [0...|mcm|1462553643217|\n",
      "|[619e9dd8677066b2...|2481628092|[[1.124699285, [0...|mcm|1462553705002|\n",
      "|[619e9dd8677066b2...|2481633423|[[1.124699285, [0...|mcm|1462553765802|\n",
      "|[619e9dd8677066b2...|2481879973|[[1.124699285, [0...|mcm|1462556181157|\n",
      "|[619e9dd8677066b2...|2481938295|[[1.124699285, [0...|mcm|1462556825096|\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699278, [0...|mcm|1462537993283|\n",
      "|[619e9dd8677066b2...|2480180647|[[1.124699278, [0...|mcm|1462539270638|\n",
      "+--------------------+----------+--------------------+---+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"select * from mongo array_contains(root.mc, array('CLOSED'))\").show()\n",
    "from pyspark.sql.functions import explode   # Explodes lists into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_exploded = df.select('*', explode(df.mc).alias('mc_row'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_only = mc_exploded.filter(mc_exploded.mc_row.marketDefinition.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+---+-------------+--------------------+\n",
      "|                 _id|       clk|                  mc| op|           pt|              mc_row|\n",
      "+--------------------+----------+--------------------+---+-------------+--------------------+\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699287, [0...|mcm|1462537993283|[1.124699287, [0,...|\n",
      "|[619e9dd8677066b2...|2480249142|[[1.124699287, [0...|mcm|1462540135101|[1.124699287, [0,...|\n",
      "|[619e9dd8677066b2...|2481803835|[[1.124699287, [0...|mcm|1462555384075|[1.124699287, [0,...|\n",
      "|[619e9dd8677066b2...|2482083965|[[1.124699287, [0...|mcm|1462558199155|[1.124699287, [0,...|\n",
      "|[619e9dd8677066b2...|2482177634|[[1.124699287, [0...|mcm|1462559078531|[1.124699287, [0,...|\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699285, [0...|mcm|1462537993283|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2480212422|[[1.124699285, [0...|mcm|1462539800697|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2480409166|[[1.124699285, [0...|mcm|1462541919372|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2481622628|[[1.124699285, [0...|mcm|1462553643217|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2481628092|[[1.124699285, [0...|mcm|1462553705002|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2481633423|[[1.124699285, [0...|mcm|1462553765802|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2481879973|[[1.124699285, [0...|mcm|1462556181157|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2481938295|[[1.124699285, [0...|mcm|1462556825096|[1.124699285, [0,...|\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699278, [0...|mcm|1462537993283|[1.124699278, [0,...|\n",
      "|[619e9dd8677066b2...|2480180647|[[1.124699278, [0...|mcm|1462539270638|[1.124699278, [0,...|\n",
      "|[619e9dd8677066b2...|2481407254|[[1.124699278, [0...|mcm|1462551952407|[1.124699278, [0,...|\n",
      "|[619e9dd8677066b2...|2481698341|[[1.124699278, [0...|mcm|1462554327642|[1.124699278, [0,...|\n",
      "|[619e9dd8677066b2...|2481740307|[[1.124699278, [0...|mcm|1462554768806|[1.124699278, [0,...|\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699287, [0...|mcm|1462537993283|[1.124699287, [0,...|\n",
      "|[619e9dd8677066b2...|2480088678|[[1.124699287, [0...|mcm|1462537993283|[1.124699278, [0,...|\n",
      "+--------------------+----------+--------------------+---+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md_only.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the marketDefinition array.\n",
    "market_definitions = md_only.selectExpr('op AS operation_type',\n",
    "                                        'clk AS sequence_token',\n",
    "                                        'pt AS published_time',\n",
    "                                        'mc_row.id AS market_id',\n",
    "                                        'mc_row.rc AS rc',\n",
    "                                        'mc_row.marketDefinition.betDelay AS bet_delay',\n",
    "                                        'mc_row.marketDefinition.bettingType AS betting_type',\n",
    "                                        'mc_row.marketDefinition.bspMarket AS bsp_market',\n",
    "                                        'mc_row.marketDefinition.bspReconciled AS bsp_reconciled',\n",
    "                                        'mc_row.marketDefinition.complete AS complete',\n",
    "                                        'mc_row.marketDefinition.countryCode AS country_code',\n",
    "                                        'mc_row.marketDefinition.crossMatching AS cross_matching',\n",
    "                                        'mc_row.marketDefinition.discountAllowed AS discount_allowed',\n",
    "                                        'mc_row.marketDefinition.eventId AS event_id',\n",
    "                                        'mc_row.marketDefinition.eventName AS event_name',\n",
    "                                        'mc_row.marketDefinition.eventTypeId AS event_type_id',\n",
    "                                        'mc_row.marketDefinition.inPlay AS in_play',\n",
    "                                        'mc_row.marketDefinition.marketBaseRate AS market_base_rate',\n",
    "                                        'mc_row.marketDefinition.marketTime AS market_time',\n",
    "                                        'mc_row.marketDefinition.marketType AS market_type',\n",
    "                                        'mc_row.marketDefinition.numberOfActiveRunners AS number_of_active_runners',\n",
    "                                        'mc_row.marketDefinition.numberOfWinners AS number_of_winners',\n",
    "                                        'mc_row.marketDefinition.openDate AS open_date',\n",
    "                                        'mc_row.marketDefinition.persistenceEnabled AS persistence_enabled',\n",
    "                                        'mc_row.marketDefinition.runnersVoidable AS runners_voidable',\n",
    "                                        'mc_row.marketDefinition.settledTime AS settled_time',\n",
    "                                        'mc_row.marketDefinition.status AS status',\n",
    "                                        'mc_row.marketDefinition.suspendTime AS suspend_time',\n",
    "                                        'mc_row.marketDefinition.timezone AS timezone',\n",
    "                                        'mc_row.marketDefinition.turnInPlayEnabled AS turn_in_play_enabled',\n",
    "                                        'mc_row.marketDefinition.version AS version',\n",
    "                                        'mc_row.marketDefinition.name AS market_name',\n",
    "                                        'mc_row.marketDefinition.regulators AS regulators',\n",
    "                                        'mc_row.marketDefinition.runners AS runners')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_definitions = market_definitions.filter(market_definitions[\"status\"]==\"CLOSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_definitions = market_definitions.filter(market_definitions[\"market_type\"]==\"WIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_only = market_definitions.filter(market_definitions.runners.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the Runners array.\n",
    "runners_exploded = runners_only.select(market_definitions.operation_type,\n",
    "                                       market_definitions.published_time,\n",
    "                                       market_definitions.market_id,\n",
    "                                       market_definitions.market_name,\n",
    "                                       market_definitions.event_id,\n",
    "                                       market_definitions.event_name,\n",
    "                                       explode(market_definitions.runners).alias('runner_row'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_exploded = runners_exploded.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "##### new dataset (just added BSP to the runners dataframe created above)\n",
    "runners_exploded_wbsp = runners_only.select(market_definitions.operation_type,\n",
    "                                       market_definitions.published_time,\n",
    "                                       market_definitions.market_id,\n",
    "                                       market_definitions.market_name,\n",
    "                                       market_definitions.event_id,\n",
    "                                       market_definitions.event_name,\n",
    "                                       explode(market_definitions.runners).alias('runner_row'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### new dataset (just added BSP to the runners dataframe created above)\n",
    "runners_wbsp = runners_exploded_wbsp.selectExpr('operation_type',\n",
    "                                      'published_time',\n",
    "                                      'market_id',\n",
    "                                      'market_name',\n",
    "                                      'event_id',\n",
    "                                      'event_name',\n",
    "                                      'runner_row.id AS runner_id',\n",
    "                                      'runner_row.name AS runner_name',\n",
    "                                      'runner_row.status AS runner_status',\n",
    "                                      'runner_row.bsp AS bsp',\n",
    "                                      'runner_row.sortPriority AS runner_sort_priority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### new dataset (just added BSP to the runners dataframe created above)\n",
    "runners_wbsp = runners_wbsp.filter(runners_wbsp.runner_status!='REMOVED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### new dataset (just added BSP to the runners dataframe created above)\n",
    "#runners_wbsp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the useful fields, and give them user friendly names.\n",
    "runners = runners_exploded.selectExpr('operation_type',\n",
    "                                      'published_time',\n",
    "                                      'market_id',\n",
    "                                      'market_name',\n",
    "                                      'event_id',\n",
    "                                      'event_name',\n",
    "                                      'runner_row.id AS runner_id',\n",
    "                                      'runner_row.name AS runner_name',\n",
    "                                      'runner_row.status AS runner_status',\n",
    "                                      'runner_row.sortPriority AS runner_sort_priority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to only the records that have rc (runner changes).\n",
    "rc_only = mc_exploded.filter(mc_exploded.mc_row.rc.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the rc (runner changes) array.\n",
    "rc_exploded = rc_only.select(rc_only.op.alias('operation_type'),\n",
    "                             rc_only.pt.alias('published_time'),\n",
    "                             rc_only.mc_row.id.alias('market_id'),\n",
    "                             explode(rc_only.mc_row.rc).alias('runner_change_row'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the useful fields, and give them user friendly names.\n",
    "runner_changes = rc_exploded.selectExpr('operation_type',\n",
    "                                        'published_time',\n",
    "                                        'market_id',\n",
    "                                        'runner_change_row.id AS runner_id',\n",
    "                                        'runner_change_row.ltp AS last_traded_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.researchgate.net/publication/351844751_Sonic_Thunder_vs_Brian_the_Snail_Are_people_affected_by_uninformative_racehorse_names\n",
    "fast_names = [\n",
    "    'a mile a minute', 'helter-skelter', 'quick-fire',\n",
    "    'apace', 'high-speed quickly',\n",
    "    'as fast as your legs would carry you',\n",
    "    'hot', 'quickness',\n",
    "    'as if it is going out of style', 'hotfoot', 'rapid',\n",
    "    'at a rate of knots', 'hustle', 'rapid-fire',\n",
    "    'at full pelt', 'in the twinkling of an eye',\n",
    "    'rate',\n",
    "    'at full speed', 'Jack Robinson', 'say',\n",
    "    'at full tilt', 'lick', 'shot',\n",
    "    'at full tilt', 'lickety-split', 'smartly',\n",
    "    'before you can say Jack Robinson', 'lightning', 'souped-up',\n",
    "    'blistering', 'like a shot', 'spanking',\n",
    "    'breakneck' 'like a streak of lightning', 'speed',\n",
    "    'brisk' 'like lightning spread', 'like wildfire',\n",
    "    'chop-chop', 'meteoric', 'streak',\n",
    "    'crash', 'mile', 'style',\n",
    "    'express', 'nimble', 'superfast',\n",
    "    'fast', 'nimbleness', 'supersonic',\n",
    "\n",
    "    'fleet', 'nimbly', 'swift',\n",
    "    'full', 'nippy', 'swiftly',\n",
    "    'full steam ahead', 'pdq', 'thick',\n",
    "    'gallop', 'pell-mell', 'thick and fast',\n",
    "    'galloping', 'poky', 'tilt',\n",
    "    'go like hot cakes', 'posthaste', 'top',\n",
    "    'have a heavy foot', 'precipitous', 'twinkling',\n",
    "    'headlong', 'precipitously', 'whoosh',\n",
    "    'heavy', 'prompt', 'wildfire',\n",
    "    'hell', 'promptly', 'zippy',\n",
    "    'hell for leather', 'quick',\n",
    "\n",
    "\n",
    "    'accelerated', 'high-speed', 'pell-mell',\n",
    "    'at full speed', 'hurried', 'post-haste',\n",
    "    'at full tilt', 'hurriedly', 'quick',\n",
    "    'at speed', 'in a flash', 'quickly',\n",
    "    'at the speed of light', 'in a hurry', 'rapid',\n",
    "    'blistering', 'in a trice', 'rapidly',\n",
    "    'breakneck', 'in a wink', 'smart',\n",
    "    'brisk', 'in haste', 'speedily',\n",
    "    'briskly', 'in time', 'speedy',\n",
    "    'energetically', 'in no time at all', 'sporty',\n",
    "    'expeditious', 'in the blink of an eye', 'sprightly',\n",
    "    'expeditiously', 'like a flash', 'swift',\n",
    "    'express', 'like a shot', 'swiftly',\n",
    "    'fast', 'like an arrow from a bow', 'turbo',\n",
    "    'fast-moving', 'lively', 'unhesitating',\n",
    "    'fleet-footed', 'meteoric', 'whirlwind',\n",
    "    'flying', 'nimble', 'with all haste',\n",
    "    'hastily', 'on the double', 'with dispatch',\n",
    "    'hasty', 'pell-mell', 'without delay',\n",
    "\n",
    "    'acceleration', 'haste', 'scutter',\n",
    "    'alacrity', 'hasten', 'sharpness',\n",
    "    'blast', 'hurriedness', 'shoot',\n",
    "    'bolt', 'hurry', 'spank along',\n",
    "    'bowl along', 'hurry', 'speed',\n",
    "    'briskness', 'hurtle', 'speediness',\n",
    "    'career', 'immediacy', 'sprint',\n",
    "    'celerity', 'momentum', 'stampede',\n",
    "    'charge', 'pace', 'streak',\n",
    "    'dart', 'precipitateness', 'sweep',\n",
    "    'dash', 'promptness', 'swiftness',\n",
    "    'dispatch', 'quickness', 'swoop',\n",
    "    'expedition', 'race', 'tempo',\n",
    "    'expeditiousness', 'rapidity', 'uzz',\n",
    "    'fastness', 'rate', 'velocity',\n",
    "    'flash', 'rattle along', 'whirl',\n",
    "    'fly', 'run', 'whizz',\n",
    "    'gallop', 'rush', 'whoosh',\n",
    "    'go hell for leather', 'scramble', 'wing',\n",
    "    'go like lightning', 'scud', 'zoom',\n",
    "    'hare', 'scurry',\n",
    "\n",
    "    'abrupt', 'impetuous', 'rushed',\n",
    "    'agility', 'outrun', 'scramble',\n",
    "    'dash', 'overhasty', 'speed',\n",
    "    'disconcerted', 'overrun', 'speedily',\n",
    "    'dodge', 'promptly', 'speedy',\n",
    "    'haste', 'quick', 'sudden',\n",
    "    'hastily', 'quickly', 'suddenly',\n",
    "    'hurried', 'rapid', 'swift',\n",
    "    'hurriedly', 'rapidly', 'swiftly',\n",
    "    'hurry', 'rush', 'zoom',\n",
    "\n",
    "    'accelerate', 'haste', 'race',\n",
    "    'acceleration', 'hasten', 'rapidity',\n",
    "    'agility', 'hie', 'rush',\n",
    "    'airspeed', 'hurriedly', 'speedy',\n",
    "    'celerity', 'hurry', 'stronghold',\n",
    "    'dash', 'pace', 'swift',\n",
    "    'decelerate', 'quick', 'swiftness',\n",
    "    'expedite', 'quicken', 'tempo',\n",
    "    'fast', 'quickly', 'urgently',\n",
    "    'fastness', 'quickness', 'velocity',\n",
    "\n",
    "    'Apache', 'Bentley', 'Blustery',\n",
    "    'Bullet', 'Buzz', 'Comet',\n",
    "    ',Cougar', ',Falcon', 'Faster',\n",
    "    'Flash', 'Ghost', 'rider', 'Harley',\n",
    "    'Jet', 'Jump', 'Jumping',\n",
    "    'Miles', 'Mustang', 'Pony express',\n",
    "    'Quick', 'Quicky', 'Racer',\n",
    "    'Rapid', 'Rapide', 'Rocket',\n",
    "    'Sonic', 'Speedy', 'Taz',\n",
    "    'Tornado', 'Traveler', 'Wildfire',\n",
    "    'Voyager', 'Wild', 'Velocity', \n",
    "\n",
    "    'Sonic Power', 'Speed Dragon', 'Zippy Lad', 'Lightening Vault',\n",
    "    'Powerful Jet', 'Orbit Express', 'Swift Chap', 'Blazing Tempo',\n",
    "    'Brave Falcon', 'Rush Now', 'Top Magic', 'Dixie Flyer',\n",
    "    'Esprit De Bullet', 'Strike Fast', 'Hustle Hard', 'Diamond Rush',\n",
    "    'Crown Me Fast', 'Hot Seat', 'Top Gear', 'Bright Bullet',\n",
    "    'Quick Art', 'Rush Of Blood', 'Top Boy', 'Meteoric',\n",
    "    'Moments',\n",
    "    'One Wild Guy', 'Sonic Thunder', 'Grand Gallop', 'Zippy Speed',\n",
    "    'Run for Roses', 'Saratoga',\n",
    "    'Wildcat',\n",
    "    'Quick Beers', 'Sudden Rush',\n",
    "    'Flyingwithoutwings', 'Fast On', 'Dazzlem Quick', 'You Drive I Fly',\n",
    "    'Irish Rocket', 'Hot Sauce', 'Mighty Flying', 'frost'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fast_names)):\n",
    "    fast_names[i] = fast_names[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners = runners.filter(runners.runner_status!='REMOVED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(BooleanType())\n",
    "def is_fast(name):\n",
    "    if name is None:\n",
    "        return False\n",
    "    name = name.lower()\n",
    "    for s in fast_names:\n",
    "        if s in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast = runners.withColumn('is_fast_horse',  is_fast(runners.runner_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### aisling with bsp data\n",
    "runners_fast_wbsp = runners_wbsp.withColumn('is_fast_horse',  is_fast(runners_wbsp.runner_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aisling with bsp data\n",
    "runners_fast_wbsp = runners_fast_wbsp.filter(runners_fast_wbsp.bsp.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_wbsp = runners_fast_wbsp.filter(runners_fast_wbsp.bsp!='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_wbsp = runners_fast_wbsp.filter(runners_fast_wbsp.bsp!='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('operation_type', 'string'),\n",
       " ('published_time', 'bigint'),\n",
       " ('market_id', 'string'),\n",
       " ('market_name', 'string'),\n",
       " ('event_id', 'string'),\n",
       " ('event_name', 'string'),\n",
       " ('runner_id', 'int'),\n",
       " ('runner_name', 'string'),\n",
       " ('runner_status', 'string'),\n",
       " ('bsp', 'string'),\n",
       " ('runner_sort_priority', 'int'),\n",
       " ('is_fast_horse', 'boolean')]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runners_fast_wbsp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-----------+---------------+--------+-------------------+---------+------------------+-------------+------+--------------------+-------------+\n",
      "|operation_type|published_time|  market_id|    market_name|event_id|         event_name|runner_id|       runner_name|runner_status|   bsp|runner_sort_priority|is_fast_horse|\n",
      "+--------------+--------------+-----------+---------------+--------+-------------------+---------+------------------+-------------+------+--------------------+-------------+\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10575249|       Bitsys Half|        LOSER|  13.5|                   5|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10288198|         Blue Code|        LOSER|  32.0|                   6|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10116126|            Zartan|        LOSER| 57.95|                   7|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10221428|         Old Conch|        LOSER|223.91|                   8|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10150151|Rose Needs A Check|        LOSER| 15.34|                   9|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10237987|           Make Do|        LOSER|  10.5|                  10|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10674850|      Cajun Kitten|        LOSER|   4.0|                  11|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10550376|       Dr. Zipcity|       WINNER| 26.28|                  12|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10849769|     Goforthegreen|        LOSER|  21.0|                  13|        false|\n",
      "|           mcm| 1462501034557|1.124659130|     R8 1m Allw|27784588|EvangD (US) 5th May| 10762541|       Specialeyes|        LOSER|  2.31|                  14|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May| 10175250|           Cabildo|        LOSER| 83.46|                   1|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May| 10592064|      Point Secret|        LOSER|   5.6|                   2|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May|  9111702|       Lip Service|       WINNER|   4.0|                   3|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May| 10154653|         Warlander|        LOSER|   7.0|                   4|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May| 10059993|    Cowboy Classic|        LOSER| 12.07|                   5|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May| 10681528|    Dry Wood Creek|        LOSER|   4.4|                   6|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May| 10804072|              Eppy|        LOSER| 18.52|                   7|        false|\n",
      "|           mcm| 1462502535129|1.124659133|R9 7f Mdn Claim|27784588|EvangD (US) 5th May| 10882521|     Ball And Pins|        LOSER| 14.54|                   8|        false|\n",
      "|           mcm| 1462495994956|1.124659121|    R5 6f Claim|27784588|EvangD (US) 5th May| 10102626|       Philli Four|        LOSER| 14.99|                   1|        false|\n",
      "|           mcm| 1462495994956|1.124659121|    R5 6f Claim|27784588|EvangD (US) 5th May| 10134313|    Lydgate Affair|        LOSER| 38.42|                   2|        false|\n",
      "+--------------+--------------+-----------+---------------+--------+-------------------+---------+------------------+-------------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runners_fast_wbsp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turning bsp to integer type\n",
    "from pyspark.sql.types import IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_wbsp = runners_fast_wbsp.withColumn(\"bsp\", runners_fast_wbsp[\"bsp\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('operation_type', 'string'),\n",
       " ('published_time', 'bigint'),\n",
       " ('market_id', 'string'),\n",
       " ('market_name', 'string'),\n",
       " ('event_id', 'string'),\n",
       " ('event_name', 'string'),\n",
       " ('runner_id', 'int'),\n",
       " ('runner_name', 'string'),\n",
       " ('runner_status', 'string'),\n",
       " ('bsp', 'int'),\n",
       " ('runner_sort_priority', 'int'),\n",
       " ('is_fast_horse', 'boolean')]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runners_fast_wbsp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('operation_type', 'string'),\n",
       " ('published_time', 'bigint'),\n",
       " ('market_id', 'string'),\n",
       " ('market_name', 'string'),\n",
       " ('event_id', 'string'),\n",
       " ('event_name', 'string'),\n",
       " ('runner_id', 'int'),\n",
       " ('runner_name', 'string'),\n",
       " ('runner_status', 'string'),\n",
       " ('runner_sort_priority', 'int'),\n",
       " ('is_fast_horse', 'boolean')]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runners_fast.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_only = runners_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_only = runners_fast.filter(runners_fast.is_fast_horse=='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_only.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_only_win = runners_fast_only.filter(runners_fast_only.runner_status=='WINNER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_only_win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample = runners_fast_wbsp.limit(1000)\n",
    "runners_fast_wbsp_sample = runners_fast_wbsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "label_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('operation_type', 'string'),\n",
    " ('published_time', 'bigint'),\n",
    " ('market_id', 'string'),\n",
    " ('market_name', 'string'),\n",
    " ('event_id', 'string'),\n",
    " ('event_name', 'string'),\n",
    " ('runner_id', 'int'),\n",
    " ('runner_name', 'string'),\n",
    " ('runner_status', 'string'),\n",
    " ('runner_sort_priority', 'int'),\n",
    " ('is_fast_horse', 'boolean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['operation_type', 'published_time', 'market_id', 'market_name', 'event_id', 'event_name', 'runner_id', 'runner_name', 'runner_sort_priority' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_wbsp_sample1 = runners_fast_wbsp_sample.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sum of two or more columns in pyspark\n",
    "\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_wbsp_sample2=runners_fast_wbsp_sample1.withColumn(\"implied_prob\", 1/col(\"bsp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"bsp\"]\n",
    "runners_fast_wbsp_sample2 = runners_fast_wbsp_sample2.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample2.groupby(\"runner_status\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample2.groupby(\"is_fast_horse\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_wbsp_sample2 = runners_fast_wbsp_sample2.withColumn(\"is_fast_horse_num\", runners_fast_wbsp_sample2[\"is_fast_horse\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_fast_wbsp_sample2 = runners_fast_wbsp_sample2.drop(\"is_fast_horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('runner_status', 'string'),\n",
       " ('implied_prob', 'double'),\n",
       " ('is_fast_horse_num', 'int')]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runners_fast_wbsp_sample2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_fast_wbsp_sample2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = runners_fast_wbsp_sample2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "categoricalColumns = ['is_fast_horse_num']\n",
    "#  is_fast_horse, runner_status, implied_prob\n",
    "stages = []\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = 'runner_status', outputCol = 'label')\n",
    "\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "numericCols = ['implied_prob']\n",
    "\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\", handleInvalid='skip')\n",
    "\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# pipline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(runners_fast_wbsp_sample2)\n",
    "runners_fast_wbsp_sample2 = pipelineModel.transform(runners_fast_wbsp_sample2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- runner_status: string (nullable = true)\n",
      " |-- implied_prob: double (nullable = true)\n",
      " |-- is_fast_horse_num: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selectedCols = ['label', 'features'] + cols\n",
    "runners_fast_wbsp_sample2 = runners_fast_wbsp_sample2.select(selectedCols)\n",
    "runners_fast_wbsp_sample2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=DenseVector([1.0, 0.0769]), runner_status='LOSER', implied_prob=0.07692307692307693, is_fast_horse_num=0)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runners_fast_wbsp_sample2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('label', 'double'),\n",
       " ('features', 'vector'),\n",
       " ('runner_status', 'string'),\n",
       " ('implied_prob', 'double'),\n",
       " ('is_fast_horse_num', 'int')]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runners_fast_wbsp_sample2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>[1.0, 0.07692307692307693]</td>\n",
       "      <td>[1.0, 0.03125]</td>\n",
       "      <td>[1.0, 0.017543859649122806]</td>\n",
       "      <td>[1.0, 0.004484304932735426]</td>\n",
       "      <td>[1.0, 0.06666666666666667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runner_status</th>\n",
       "      <td>LOSER</td>\n",
       "      <td>LOSER</td>\n",
       "      <td>LOSER</td>\n",
       "      <td>LOSER</td>\n",
       "      <td>LOSER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implied_prob</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_fast_horse_num</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0               1  \\\n",
       "label                                     0.0             0.0   \n",
       "features           [1.0, 0.07692307692307693]  [1.0, 0.03125]   \n",
       "runner_status                           LOSER           LOSER   \n",
       "implied_prob                         0.076923         0.03125   \n",
       "is_fast_horse_num                           0               0   \n",
       "\n",
       "                                             2                            3  \\\n",
       "label                                      0.0                          0.0   \n",
       "features           [1.0, 0.017543859649122806]  [1.0, 0.004484304932735426]   \n",
       "runner_status                            LOSER                        LOSER   \n",
       "implied_prob                          0.017544                     0.004484   \n",
       "is_fast_horse_num                            0                            0   \n",
       "\n",
       "                                            4  \n",
       "label                                     0.0  \n",
       "features           [1.0, 0.06666666666666667]  \n",
       "runner_status                           LOSER  \n",
       "implied_prob                         0.066667  \n",
       "is_fast_horse_num                           0  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(runners_fast_wbsp_sample2.take(5), columns=runners_fast_wbsp_sample2.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector, runner_status: string, implied_prob: double, is_fast_horse_num: int]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runners_fast_wbsp_sample2.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 622555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 249:====================================================>(113 + 1) / 114]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 266398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train, test = runners_fast_wbsp_sample2.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2536.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:947)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6381/1882739495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelcoefficients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m names=[x[\"name\"] for x in sorted(train.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"binary\"]+\n\u001b[1;32m      5\u001b[0m    \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ml_attr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attrs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numeric\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/classification.py\u001b[0m in \u001b[0;36mcoefficients\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mAn\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthrown\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmultinomial\u001b[0m \u001b[0mlogistic\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \"\"\"\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coefficients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2536.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:947)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "modelcoefficients=np.array(lrModel.coefficients)\n",
    "\n",
    "names=[x[\"name\"] for x in sorted(train.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"binary\"]+\n",
    "   train.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"numeric\"], \n",
    "   key=lambda x: x[\"idx\"])]\n",
    "\n",
    "\n",
    "matchcoefs=np.column_stack((modelcoefficients,np.array(names)))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "matchcoefsdf=pd.DataFrame(matchcoefs)\n",
    "\n",
    "matchcoefsdf.columns=['Coefvalue', 'Feature']\n",
    "\n",
    "print(matchcoefsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_train = lrModel.transform(train)\n",
    "\n",
    "y_true = predictions_train.select(['label']).collect()\n",
    "y_pred = predictions_train.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [622718, 622419]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6381/4258809045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python37/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \"\"\"\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2076\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python37/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python37/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    331\u001b[0m         raise ValueError(\n\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [622718, 622419]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [622304, 622539]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6381/425422889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python37/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python37/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python37/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    331\u001b[0m         raise ValueError(\n\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [622304, 622539]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2254.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:947)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6381/2092419765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Beta Coefficients'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/classification.py\u001b[0m in \u001b[0;36mcoefficients\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mAn\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthrown\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmultinomial\u001b[0m \u001b[0mlogistic\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \"\"\"\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coefficients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2254.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:947)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "beta = np.sort(lrModel.coefficients)\n",
    "plt.plot(beta)\n",
    "plt.ylabel('Beta Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionTrainingSummary' object has no attribute 'roc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6381/3800920783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainingSummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FPR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TPR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'False Positive Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True Positive Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionTrainingSummary' object has no attribute 'roc'"
     ]
    }
   ],
   "source": [
    "trainingSummary = lrModel.summary\n",
    "roc = trainingSummary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionTrainingSummary' object has no attribute 'pr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6381/1850977021.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionTrainingSummary' object has no attribute 'pr'"
     ]
    }
   ],
   "source": [
    "pr = trainingSummary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 235:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|is_fast_horse_num|        implied_prob|\n",
      "+-----------------+--------------------+\n",
      "|                1|0.008333333333333333|\n",
      "|                1| 0.03333333333333333|\n",
      "|                1|0.038461538461538464|\n",
      "|                1|0.038461538461538464|\n",
      "|                1|                0.04|\n",
      "|                1|0.043478260869565216|\n",
      "|                1|              0.0625|\n",
      "|                1| 0.08333333333333333|\n",
      "|                1| 0.08333333333333333|\n",
      "|                1| 0.08333333333333333|\n",
      "+-----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.select('is_fast_horse_num', 'implied_prob').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.7916054316151564\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2254.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:947)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6381/3239265891.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/classification.py\u001b[0m in \u001b[0;36mcoefficients\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mAn\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthrown\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmultinomial\u001b[0m \u001b[0mlogistic\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \"\"\"\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coefficients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2254.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:947)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the bigger the coefficient the more predictive power it has\n",
    "\n",
    "Winner = 1, Loser = 0\n",
    "Winner = X*is_fast + Y*implied_prob\n",
    "\n",
    "\n",
    "the bigger the coefficient the more predictive power it has\n",
    "\n",
    "is_fast=0, is_not_fast=1\n",
    "Winner = 1, Loser = 0\n",
    "Winner = -0.2172*is_fast + 5.2113*implied_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multinomial coefficients: \" + str(lrModel.coefficientMatrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multinomial intercepts: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd= test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "x_test1 = np.linspace(0.0,1.0,num=288)\n",
    "# predict dummy y_test data based on the logistic model\n",
    "y_test = x_test1 * lrModel.coefficients[1] + x_test1 * lrModel.coefficients[0] + lrModel.interceptVector\n",
    "#y_test = x_test * 4 + 2\n",
    "    \n",
    "sigmoid = expit(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "#sigmoid = expit(list(test_pd.label))\n",
    "#plt.scatter(iris_data[:,0],iris_target, c=iris_target,label = \"sepal length\")\n",
    "plt.scatter(list(test_pd.implied_prob), test_pd.label) \n",
    "# ravel to convert the 2-d array to a flat array\n",
    "plt.plot(x_test1,sigmoid.ravel(),c=\"green\", label = \"logistic fit\")\n",
    "plt.yticks([0, 0.2, 0.4, 0.5, 0.6, 0.7, 1])\n",
    "plt.axhline(.5, color=\"red\", label=\"cutoff\")\n",
    "plt.xlim([0, 1])\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connector is called 'mysql-connector-python'\n",
    "# Google it and what you want to do\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"mysql\",\n",
    "  user=\"ssbd\",\n",
    "  password=\"pass\",\n",
    "  database='analysis_db'\n",
    ")\n",
    "\n",
    "print(mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/44893565/get-list-of-mysql-databases-with-python\n",
    "cursor = mydb.cursor()\n",
    "databases = (\"show databases\")\n",
    "cursor.execute(databases)\n",
    "for (databases) in cursor:\n",
    "     print (databases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/how-to-show-all-tables-in-mysql-using-python/\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"Show tables;\")\n",
    "myresult = mycursor.fetchall()\n",
    " \n",
    "for x in myresult:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runners_wbsp.filter(runners_wbsp[\"runner_name\"]==\"14.Coisa Boa\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling\n",
    "df_class_0 = train[train['label'] == 0]\n",
    "df_class_1 = train[train['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(withReplacement=True,fraction=6.9)\n",
    "train_over = df_class_0.union(df_class_1_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel_over = lr.fit(train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "modelcoefficients=np.array(lrModel_over.coefficients)\n",
    "\n",
    "names=[x[\"name\"] for x in sorted(train.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"binary\"]+\n",
    "   train.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"numeric\"], \n",
    "   key=lambda x: x[\"idx\"])]\n",
    "\n",
    "\n",
    "matchcoefs=np.column_stack((modelcoefficients,np.array(names)))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "matchcoefsdf=pd.DataFrame(matchcoefs)\n",
    "\n",
    "matchcoefsdf.columns=['Coefvalue', 'Feature']\n",
    "\n",
    "print(matchcoefsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = lrModel_over.transform(train_over)\n",
    "\n",
    "y_true = predictions_train.select(['label']).collect()\n",
    "y_pred = predictions_train.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "x_test1 = np.linspace(0.0,1.0,num=288)\n",
    "# predict dummy y_test data based on the logistic model\n",
    "y_test = x_test1 * lrModel_over.coefficients[1] + x_test1 * lrModel_over.coefficients[0] + lrModel_over.interceptVector\n",
    "#y_test = x_test * 4 + 2\n",
    "    \n",
    "sigmoid = expit(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "#sigmoid = expit(list(test_pd.label))\n",
    "#plt.scatter(iris_data[:,0],iris_target, c=iris_target,label = \"sepal length\")\n",
    "plt.scatter(list(test_pd.implied_prob), test_pd.label) \n",
    "# ravel to convert the 2-d array to a flat array\n",
    "plt.plot(x_test1,sigmoid.ravel(),c=\"green\", label = \"logistic fit\")\n",
    "plt.yticks([0, 0.2, 0.4, 0.5, 0.6, 0.7, 1])\n",
    "plt.axhline(.5, color=\"red\", label=\"cutoff\")\n",
    "plt.xlim([0, 1])\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
